{
  "hash": "484cdfaca13647a2ea2eb50a845e9b9c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nexecute:\n  echo: true\n  eval: true\n  warning: true\n  error: true \ntitle: \"Gradient Boosting\"\nauthor: \"Noah Geller\"\ndate: \"10/30/24\"\n---\n\n::: {#ba5fc57c .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np \nimport matplotlib.pyplot as plt\nx = np.random.rand(10)\ny = np.random.rand(10)\nplt.scatter(x,y)\n```\n\n::: {.cell-output .cell-output-display}\n![](boosting_files/figure-html/cell-2-output-1.png){width=571 height=411}\n:::\n:::\n\n\n::: {#7cc6f553 .cell execution_count=2}\n``` {.python .cell-code}\nfor i in np.arange(10):\n  print(i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n```\n:::\n:::\n\n\n::: {#e4ea8841 .cell execution_count=3}\n``` {.python .cell-code}\nnp.random.binomial(1,0.5)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n1\n```\n:::\n:::\n\n\nThe standard setup of a predictive machine learning problem consists of: \n\n  - An outcome variable $y\\in \\mathcal{Y}$ that you want to predict.\n\n  - A collection of features $X = x_1,\\dots,x_p \\in \\mathcal{X}$ which you believe can help you predict $y$. \n\n  - A finite data set of pairs $\\{(X_i,y_i)\\}_{i=1}^n\\subset \\mathcal{X}\\times\\mathcal{Y}$.\n\n  - A hypothesis class of predictive functions $\\mathcal{F}\\subset \\mathcal{Y}^\\mathcal{X}$. \n  \n  - A loss function $L:\\mathcal{F} \\times \\mathcal{X}\\times \\mathcal{Y} \\to \\mathbb{R}$ which describes how poorly a candidate predictor $f\\in \\mathcal{F}$ performs on a known pair $(X,y)$. \n\nThe goal is then to find the predictor $f\\in \\mathcal{F}$ which minimizes the expected loss over all possible $(X,y)$ pairs. We only have access to a finite sample from the true joint distribution of $X$ and $y$, so we usually define \n$$\\mathscr{L}(f) = \\frac{1}{n}\\sum_{i=1}^n L(f,X_i,y_i)$$\nto be the average loss of a predictor over the whole training dataset and seek to minimize this quantity as a proxy for minmizing the expected loss over the true distribution.  \n\nThe most straightforward way to make this problem computationally tractable is to choose a hypothesis class $\\mathcal{F}$ which can be parameterized by a finite dimensional Euclidean space and a loss function $L$ which is differentiable with respect to those parameters. This allows us to exploit the miraculous power of (stochastic) gradient descent to find a vector of parameters which (locally) minimizes $\\mathscr{L}$. Although we usually think of gradient descent as just an iterative algorithm that continually updates our candidate vector of parameters, we can also remember our previous steps and write the $k$'th iteration as the sum\n\n\\begin{align*}\n\\theta_k &= \\theta_0 - \\rho_1 \\nabla_\\theta \\mathscr{L}(f_{\\theta_0}) - \\rho_2 \\nabla_\\theta \\mathscr{L}(f_{\\theta_1}) - \\dots \\\\\n&= \\theta_0 + \\sum_{i=1}^k -\\rho_k \\nabla_\\theta \\mathscr{L}(f_{\\theta_{k-1}})\n\\end{align*}\nwhere $\\rho_i$ is the $i$'th step size (perhaps obtained by doing a line search) and $f_{\\theta_i}$ is the predictive function corresponding to the parameters $\\theta_i$. \n\nIn order to make the jump from gradient descent to gradient boosting, let's forget for a moment that we live in the real world and think about what we could do if we had some magic at our disposal. \nIn the process we just layed out, the biggest compromise we made was restricting our hypothesis class of functions to be one that can be parameterized by finitely many parameters. \n\n",
    "supporting": [
      "boosting_files"
    ],
    "filters": [],
    "includes": {}
  }
}